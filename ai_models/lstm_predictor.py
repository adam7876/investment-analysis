#!/usr/bin/env python3
"""
LSTMè‚¡åƒ¹é æ¸¬æ¨¡å‹
ä½¿ç”¨æ·±åº¦å­¸ç¿’é€²è¡Œæ™‚é–“åºåˆ—é æ¸¬ï¼Œæå‡ç³»çµ±AIèƒ½åŠ›
"""

import numpy as np
import pandas as pd
import yfinance as yf
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_squared_error, mean_absolute_error
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout, BatchNormalization
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau
import matplotlib.pyplot as plt
from datetime import datetime, timedelta
from loguru import logger
from typing import Dict, List, Tuple, Optional
import joblib
import os

class LSTMStockPredictor:
    """LSTMè‚¡åƒ¹é æ¸¬å™¨"""
    
    def __init__(self, sequence_length: int = 60, prediction_days: int = 1):
        self.sequence_length = sequence_length  # ä½¿ç”¨éå»60å¤©æ•¸æ“š
        self.prediction_days = prediction_days  # é æ¸¬æœªä¾†1å¤©
        self.model = None
        self.scaler = MinMaxScaler(feature_range=(0, 1))
        self.feature_columns = [
            'Close', 'Volume', 'High', 'Low', 'Open',
            'MA_5', 'MA_10', 'MA_20', 'MA_50',
            'RSI', 'MACD', 'BB_upper', 'BB_lower', 'Volatility'
        ]
        
    def prepare_features(self, data: pd.DataFrame) -> pd.DataFrame:
        """æº–å‚™ç‰¹å¾µæ•¸æ“š"""
        df = data.copy()
        
        # ç§»å‹•å¹³å‡ç·š
        df['MA_5'] = df['Close'].rolling(window=5).mean()
        df['MA_10'] = df['Close'].rolling(window=10).mean()
        df['MA_20'] = df['Close'].rolling(window=20).mean()
        df['MA_50'] = df['Close'].rolling(window=50).mean()
        
        # RSIæŒ‡æ¨™
        delta = df['Close'].diff()
        gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()
        loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
        rs = gain / loss
        df['RSI'] = 100 - (100 / (1 + rs))
        
        # MACDæŒ‡æ¨™
        exp1 = df['Close'].ewm(span=12).mean()
        exp2 = df['Close'].ewm(span=26).mean()
        df['MACD'] = exp1 - exp2
        
        # å¸ƒæ—é€šé“
        bb_period = 20
        bb_std = df['Close'].rolling(window=bb_period).std()
        bb_ma = df['Close'].rolling(window=bb_period).mean()
        df['BB_upper'] = bb_ma + (bb_std * 2)
        df['BB_lower'] = bb_ma - (bb_std * 2)
        
        # æ³¢å‹•ç‡
        df['Volatility'] = df['Close'].pct_change().rolling(window=20).std()
        
        # å¡«å……ç¼ºå¤±å€¼
        df = df.fillna(method='bfill').fillna(method='ffill')
        
        return df
    
    def create_sequences(self, data: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:
        """å‰µå»ºLSTMè¨“ç·´åºåˆ—"""
        X, y = [], []
        
        for i in range(self.sequence_length, len(data) - self.prediction_days + 1):
            # è¼¸å…¥åºåˆ—ï¼ˆéå»60å¤©çš„å¤šå€‹ç‰¹å¾µï¼‰
            X.append(data[i - self.sequence_length:i])
            # ç›®æ¨™å€¼ï¼ˆæœªä¾†1å¤©çš„æ”¶ç›¤åƒ¹ï¼‰
            y.append(data[i + self.prediction_days - 1, 0])  # æ”¶ç›¤åƒ¹åœ¨ç¬¬0åˆ—
        
        return np.array(X), np.array(y)
    
    def build_model(self, input_shape: Tuple[int, int]) -> Sequential:
        """æ§‹å»ºLSTMæ¨¡å‹"""
        model = Sequential([
            # ç¬¬ä¸€å±¤LSTM
            LSTM(units=100, return_sequences=True, input_shape=input_shape),
            Dropout(0.2),
            BatchNormalization(),
            
            # ç¬¬äºŒå±¤LSTM
            LSTM(units=100, return_sequences=True),
            Dropout(0.2),
            BatchNormalization(),
            
            # ç¬¬ä¸‰å±¤LSTM
            LSTM(units=50, return_sequences=False),
            Dropout(0.2),
            BatchNormalization(),
            
            # å…¨é€£æ¥å±¤
            Dense(units=25, activation='relu'),
            Dropout(0.1),
            
            # è¼¸å‡ºå±¤
            Dense(units=1)
        ])
        
        # ç·¨è­¯æ¨¡å‹
        model.compile(
            optimizer=Adam(learning_rate=0.001),
            loss='mse',
            metrics=['mae']
        )
        
        return model
    
    def train(self, symbol: str, period: str = "2y", validation_split: float = 0.2) -> Dict:
        """è¨“ç·´æ¨¡å‹"""
        logger.info(f"ğŸ¤– é–‹å§‹è¨“ç·´LSTMæ¨¡å‹ï¼š{symbol}")
        
        try:
            # ç²å–æ•¸æ“š
            stock_data = yf.download(symbol, period=period)
            if len(stock_data) < self.sequence_length + 50:
                raise ValueError(f"æ•¸æ“šé‡ä¸è¶³ï¼Œéœ€è¦è‡³å°‘{self.sequence_length + 50}å¤©æ•¸æ“š")
            
            # æº–å‚™ç‰¹å¾µ
            df = self.prepare_features(stock_data)
            
            # é¸æ“‡ç‰¹å¾µåˆ—
            feature_data = df[self.feature_columns].values
            
            # æ•¸æ“šæ¨™æº–åŒ–
            scaled_data = self.scaler.fit_transform(feature_data)
            
            # å‰µå»ºåºåˆ—
            X, y = self.create_sequences(scaled_data)
            
            # åˆ†å‰²è¨“ç·´å’Œé©—è­‰é›†
            split_idx = int(len(X) * (1 - validation_split))
            X_train, X_val = X[:split_idx], X[split_idx:]
            y_train, y_val = y[:split_idx], y[split_idx:]
            
            logger.info(f"è¨“ç·´é›†å¤§å°: {X_train.shape}, é©—è­‰é›†å¤§å°: {X_val.shape}")
            
            # æ§‹å»ºæ¨¡å‹
            self.model = self.build_model((X_train.shape[1], X_train.shape[2]))
            
            # è¨­ç½®å›èª¿å‡½æ•¸
            callbacks = [
                EarlyStopping(patience=10, restore_best_weights=True),
                ReduceLROnPlateau(factor=0.5, patience=5, min_lr=0.0001)
            ]
            
            # è¨“ç·´æ¨¡å‹
            history = self.model.fit(
                X_train, y_train,
                epochs=100,
                batch_size=32,
                validation_data=(X_val, y_val),
                callbacks=callbacks,
                verbose=1
            )
            
            # è©•ä¼°æ¨¡å‹
            train_pred = self.model.predict(X_train)
            val_pred = self.model.predict(X_val)
            
            # åæ¨™æº–åŒ–é æ¸¬çµæœ
            train_pred_rescaled = self.inverse_transform_predictions(train_pred)
            val_pred_rescaled = self.inverse_transform_predictions(val_pred)
            y_train_rescaled = self.inverse_transform_predictions(y_train.reshape(-1, 1))
            y_val_rescaled = self.inverse_transform_predictions(y_val.reshape(-1, 1))
            
            # è¨ˆç®—è©•ä¼°æŒ‡æ¨™
            train_rmse = np.sqrt(mean_squared_error(y_train_rescaled, train_pred_rescaled))
            val_rmse = np.sqrt(mean_squared_error(y_val_rescaled, val_pred_rescaled))
            train_mae = mean_absolute_error(y_train_rescaled, train_pred_rescaled)
            val_mae = mean_absolute_error(y_val_rescaled, val_pred_rescaled)
            
            # è¨ˆç®—æº–ç¢ºç‡ï¼ˆæ–¹å‘é æ¸¬æº–ç¢ºç‡ï¼‰
            train_direction_accuracy = self.calculate_direction_accuracy(
                y_train_rescaled, train_pred_rescaled
            )
            val_direction_accuracy = self.calculate_direction_accuracy(
                y_val_rescaled, val_pred_rescaled
            )
            
            results = {
                'symbol': symbol,
                'training_samples': len(X_train),
                'validation_samples': len(X_val),
                'train_rmse': float(train_rmse),
                'val_rmse': float(val_rmse),
                'train_mae': float(train_mae),
                'val_mae': float(val_mae),
                'train_direction_accuracy': float(train_direction_accuracy),
                'val_direction_accuracy': float(val_direction_accuracy),
                'epochs_trained': len(history.history['loss']),
                'final_loss': float(history.history['val_loss'][-1])
            }
            
            logger.info(f"âœ… æ¨¡å‹è¨“ç·´å®Œæˆ")
            logger.info(f"ğŸ“Š é©—è­‰é›†RMSE: {val_rmse:.2f}")
            logger.info(f"ğŸ“ˆ æ–¹å‘é æ¸¬æº–ç¢ºç‡: {val_direction_accuracy:.1%}")
            
            return results
            
        except Exception as e:
            logger.error(f"âŒ æ¨¡å‹è¨“ç·´å¤±æ•—: {str(e)}")
            raise
    
    def predict(self, symbol: str, days_ahead: int = 1) -> Dict:
        """é æ¸¬è‚¡åƒ¹"""
        if self.model is None:
            raise ValueError("æ¨¡å‹å°šæœªè¨“ç·´ï¼Œè«‹å…ˆèª¿ç”¨train()æ–¹æ³•")
        
        try:
            # ç²å–æœ€æ–°æ•¸æ“š
            stock_data = yf.download(symbol, period="3mo")  # ç²å–3å€‹æœˆæ•¸æ“š
            df = self.prepare_features(stock_data)
            
            # æº–å‚™æœ€æ–°çš„åºåˆ—æ•¸æ“š
            feature_data = df[self.feature_columns].values
            scaled_data = self.scaler.transform(feature_data)
            
            # å–æœ€å¾Œsequence_lengthå¤©çš„æ•¸æ“š
            last_sequence = scaled_data[-self.sequence_length:].reshape(1, self.sequence_length, -1)
            
            # é æ¸¬
            predictions = []
            current_sequence = last_sequence.copy()
            
            for _ in range(days_ahead):
                pred = self.model.predict(current_sequence, verbose=0)
                predictions.append(pred[0, 0])
                
                # æ›´æ–°åºåˆ—ï¼ˆæ»¾å‹•é æ¸¬ï¼‰
                if days_ahead > 1:
                    # å‰µå»ºæ–°çš„ç‰¹å¾µå‘é‡ï¼ˆç°¡åŒ–ç‰ˆæœ¬ï¼Œå¯¦éš›æ‡‰ç”¨ä¸­éœ€è¦æ›´è¤‡é›œçš„é‚è¼¯ï¼‰
                    new_features = current_sequence[0, -1, :].copy()
                    new_features[0] = pred[0, 0]  # æ›´æ–°æ”¶ç›¤åƒ¹
                    
                    # æ»¾å‹•æ›´æ–°åºåˆ—
                    current_sequence = np.roll(current_sequence, -1, axis=1)
                    current_sequence[0, -1, :] = new_features
            
            # åæ¨™æº–åŒ–é æ¸¬çµæœ
            predictions_rescaled = self.inverse_transform_predictions(
                np.array(predictions).reshape(-1, 1)
            )
            
            # ç²å–ç•¶å‰åƒ¹æ ¼
            current_price = float(stock_data['Close'].iloc[-1])
            
            # è¨ˆç®—é æ¸¬è®ŠåŒ–
            predicted_prices = predictions_rescaled.flatten()
            price_changes = [(price - current_price) / current_price * 100 
                           for price in predicted_prices]
            
            # ç”Ÿæˆé æ¸¬ä¿¡è™Ÿ
            signal = self.generate_trading_signal(current_price, predicted_prices[0])
            
            return {
                'symbol': symbol,
                'current_price': current_price,
                'predicted_prices': predicted_prices.tolist(),
                'price_changes': price_changes,
                'prediction_dates': self.get_prediction_dates(days_ahead),
                'trading_signal': signal,
                'confidence': self.calculate_prediction_confidence(predictions),
                'timestamp': datetime.now().isoformat()
            }
            
        except Exception as e:
            logger.error(f"âŒ é æ¸¬å¤±æ•—: {str(e)}")
            raise
    
    def inverse_transform_predictions(self, predictions: np.ndarray) -> np.ndarray:
        """åæ¨™æº–åŒ–é æ¸¬çµæœ"""
        # å‰µå»ºèˆ‡åŸå§‹ç‰¹å¾µç›¸åŒå½¢ç‹€çš„æ•¸çµ„
        dummy_features = np.zeros((predictions.shape[0], len(self.feature_columns)))
        dummy_features[:, 0] = predictions.flatten()  # æ”¶ç›¤åƒ¹åœ¨ç¬¬0åˆ—
        
        # åæ¨™æº–åŒ–
        rescaled = self.scaler.inverse_transform(dummy_features)
        return rescaled[:, 0].reshape(-1, 1)
    
    def calculate_direction_accuracy(self, actual: np.ndarray, predicted: np.ndarray) -> float:
        """è¨ˆç®—æ–¹å‘é æ¸¬æº–ç¢ºç‡"""
        if len(actual) <= 1:
            return 0.0
        
        actual_direction = np.diff(actual.flatten()) > 0
        predicted_direction = np.diff(predicted.flatten()) > 0
        
        return np.mean(actual_direction == predicted_direction)
    
    def generate_trading_signal(self, current_price: float, predicted_price: float) -> Dict:
        """ç”Ÿæˆäº¤æ˜“ä¿¡è™Ÿ"""
        change_percent = (predicted_price - current_price) / current_price * 100
        
        if change_percent > 2:
            signal = "å¼·çƒˆè²·å…¥"
            confidence = "é«˜"
        elif change_percent > 0.5:
            signal = "è²·å…¥"
            confidence = "ä¸­"
        elif change_percent < -2:
            signal = "è³£å‡º"
            confidence = "é«˜"
        elif change_percent < -0.5:
            signal = "è¬¹æ…"
            confidence = "ä¸­"
        else:
            signal = "æŒæœ‰"
            confidence = "ä½"
        
        return {
            'signal': signal,
            'confidence': confidence,
            'expected_change': round(change_percent, 2)
        }
    
    def calculate_prediction_confidence(self, predictions: List[float]) -> float:
        """è¨ˆç®—é æ¸¬ä¿¡å¿ƒåº¦"""
        # åŸºæ–¼é æ¸¬çš„ä¸€è‡´æ€§å’Œæ¨¡å‹æ€§èƒ½è¨ˆç®—ä¿¡å¿ƒåº¦
        if len(predictions) == 1:
            return 0.75  # å–®é»é æ¸¬çš„åŸºç¤ä¿¡å¿ƒåº¦
        
        # è¨ˆç®—é æ¸¬çš„è®Šç•°æ€§
        pred_std = np.std(predictions)
        pred_mean = np.mean(predictions)
        
        # è®Šç•°ä¿‚æ•¸è¶Šå°ï¼Œä¿¡å¿ƒåº¦è¶Šé«˜
        cv = pred_std / pred_mean if pred_mean != 0 else 1
        confidence = max(0.5, 1 - cv)
        
        return min(0.95, confidence)
    
    def get_prediction_dates(self, days_ahead: int) -> List[str]:
        """ç²å–é æ¸¬æ—¥æœŸ"""
        dates = []
        current_date = datetime.now()
        
        for i in range(1, days_ahead + 1):
            # è·³éé€±æœ«
            pred_date = current_date + timedelta(days=i)
            while pred_date.weekday() >= 5:  # é€±å…­=5, é€±æ—¥=6
                pred_date += timedelta(days=1)
            dates.append(pred_date.strftime('%Y-%m-%d'))
        
        return dates
    
    def save_model(self, filepath: str):
        """ä¿å­˜æ¨¡å‹"""
        if self.model is None:
            raise ValueError("æ²’æœ‰è¨“ç·´å¥½çš„æ¨¡å‹å¯ä»¥ä¿å­˜")
        
        # å‰µå»ºç›®éŒ„
        os.makedirs(os.path.dirname(filepath), exist_ok=True)
        
        # ä¿å­˜Kerasæ¨¡å‹
        self.model.save(f"{filepath}_model.h5")
        
        # ä¿å­˜æ¨™æº–åŒ–å™¨
        joblib.dump(self.scaler, f"{filepath}_scaler.pkl")
        
        logger.info(f"âœ… æ¨¡å‹å·²ä¿å­˜åˆ°: {filepath}")
    
    def load_model(self, filepath: str):
        """è¼‰å…¥æ¨¡å‹"""
        try:
            # è¼‰å…¥Kerasæ¨¡å‹
            self.model = tf.keras.models.load_model(f"{filepath}_model.h5")
            
            # è¼‰å…¥æ¨™æº–åŒ–å™¨
            self.scaler = joblib.load(f"{filepath}_scaler.pkl")
            
            logger.info(f"âœ… æ¨¡å‹å·²è¼‰å…¥: {filepath}")
            
        except Exception as e:
            logger.error(f"âŒ æ¨¡å‹è¼‰å…¥å¤±æ•—: {str(e)}")
            raise

def main():
    """ç¤ºä¾‹ç”¨æ³•"""
    # å‰µå»ºé æ¸¬å™¨
    predictor = LSTMStockPredictor(sequence_length=60)
    
    # è¨“ç·´æ¨¡å‹
    symbol = "AAPL"
    training_results = predictor.train(symbol, period="2y")
    
    print("\n" + "="*50)
    print("ğŸ¤– LSTMè‚¡åƒ¹é æ¸¬æ¨¡å‹è¨“ç·´çµæœ")
    print("="*50)
    print(f"è‚¡ç¥¨ä»£è™Ÿ: {training_results['symbol']}")
    print(f"é©—è­‰é›†RMSE: {training_results['val_rmse']:.2f}")
    print(f"æ–¹å‘é æ¸¬æº–ç¢ºç‡: {training_results['val_direction_accuracy']:.1%}")
    
    # é€²è¡Œé æ¸¬
    prediction_results = predictor.predict(symbol, days_ahead=5)
    
    print(f"\nğŸ“ˆ æœªä¾†5å¤©é æ¸¬çµæœ:")
    print(f"ç•¶å‰åƒ¹æ ¼: ${prediction_results['current_price']:.2f}")
    
    for i, (date, price, change) in enumerate(zip(
        prediction_results['prediction_dates'],
        prediction_results['predicted_prices'],
        prediction_results['price_changes']
    )):
        print(f"ç¬¬{i+1}å¤© ({date}): ${price:.2f} ({change:+.1f}%)")
    
    print(f"\nğŸ¯ äº¤æ˜“å»ºè­°: {prediction_results['trading_signal']['signal']}")
    print(f"ä¿¡å¿ƒåº¦: {prediction_results['confidence']:.1%}")

if __name__ == "__main__":
    main() 