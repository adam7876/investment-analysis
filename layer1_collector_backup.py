#!/usr/bin/env python3
"""
ç¬¬ä¸€å±¤æ•¸æ“šæ”¶é›†å™¨ - ç¸½ç¶“èˆ‡å¸‚å ´ç’°å¢ƒï¼ˆå¢å¼·ç‰ˆï¼‰
æ•´åˆå¤šå€‹æ•¸æ“šæºï¼Œæä¾›æ›´å¯é çš„ç¸½ç¶“æ•¸æ“šæ”¶é›†ä»‹é¢
"""

import time
import random
from datetime import datetime
from loguru import logger

from scrapers.alternative_fear_greed_scraper import AlternativeFearGreedScraper
from scrapers.macromicro_scraper import MacroMicroScraper
from scrapers.fred_api_scraper import FREDAPIScraper
from scrapers.enhanced_scrapers import EnhancedDataScraper

class Layer1Collector:
    """ç¬¬ä¸€å±¤æ•¸æ“šæ”¶é›†å™¨ï¼ˆå¢å¼·ç‰ˆï¼‰"""
    
    def __init__(self):
        self.fear_greed_scraper = AlternativeFearGreedScraper()
        self.macromicro_scraper = MacroMicroScraper()
        self.fred_scraper = FREDAPIScraper()
        self.enhanced_scraper = EnhancedDataScraper()  # æ–°å¢å¢å¼·çˆ¬èŸ²
    
    def collect_all_data(self):
        """æ”¶é›†æ‰€æœ‰ç¬¬ä¸€å±¤æ•¸æ“šï¼ˆå¢å¼·ç‰ˆï¼‰"""
        logger.info("ğŸš€ é–‹å§‹æ”¶é›†ç¬¬ä¸€å±¤ç¸½ç¶“æ•¸æ“šï¼ˆå¢å¼·ç‰ˆï¼‰")
        
        results = {
            'timestamp': datetime.now().isoformat(),
            'layer': 'Layer 1 - ç¸½ç¶“èˆ‡å¸‚å ´ç’°å¢ƒï¼ˆå¢å¼·ç‰ˆï¼‰',
            'data_sources': {},
            'enhanced_sources': {},
            'analysis': {},
            'reliability_assessment': {}
        }
        
        # === åŸæœ‰æ•¸æ“šæº ===
        
        # 1. æ”¶é›† Fear & Greed Index (Alternative.me)
        logger.info("ğŸ“Š æ”¶é›†å¸‚å ´æƒ…ç·’æ•¸æ“š...")
        try:
            fear_greed_data = self.fear_greed_scraper.scrape()
            if fear_greed_data:
                results['data_sources']['fear_greed'] = fear_greed_data
                logger.info(f"âœ… Fear & Greed Index: {fear_greed_data['index_value']} ({fear_greed_data['sentiment']})")
            else:
                logger.warning("âš ï¸ Fear & Greed Index æ•¸æ“šç²å–å¤±æ•—")
        except Exception as e:
            logger.error(f"âŒ Fear & Greed Index æ”¶é›†å¤±æ•—: {str(e)}")
        
        # éš¨æ©Ÿå»¶é²
        time.sleep(random.uniform(1, 3))
        
        # 2. æ”¶é›† FRED ç¶“æ¿Ÿæ•¸æ“š
        logger.info("ğŸ›ï¸ æ”¶é›†è¯æº–æœƒç¶“æ¿Ÿæ•¸æ“š...")
        try:
            fred_data = self.fred_scraper.scrape()
            if fred_data:
                results['data_sources']['fred'] = fred_data
                logger.info("âœ… FRED ç¶“æ¿Ÿæ•¸æ“šæ”¶é›†æˆåŠŸ")
            else:
                logger.warning("âš ï¸ FRED ç¶“æ¿Ÿæ•¸æ“šç²å–å¤±æ•—")
        except Exception as e:
            logger.error(f"âŒ FRED æ•¸æ“šæ”¶é›†å¤±æ•—: {str(e)}")
        
        # éš¨æ©Ÿå»¶é²
        time.sleep(random.uniform(2, 4))
        
        # 3. æ”¶é›† MacroMicro æ•¸æ“šï¼ˆå¯é¸ï¼‰
        logger.info("ğŸ“ˆ å˜—è©¦æ”¶é›† MacroMicro æ•¸æ“š...")
        try:
            macromicro_data = self.macromicro_scraper.scrape()
            if macromicro_data:
                results['data_sources']['macromicro'] = macromicro_data
                logger.info("âœ… MacroMicro æ•¸æ“šæ”¶é›†æˆåŠŸ")
            else:
                logger.warning("âš ï¸ MacroMicro æ•¸æ“šç²å–å¤±æ•—ï¼ˆé€™æ˜¯æ­£å¸¸çš„ï¼Œç¶²ç«™å¯èƒ½æœ‰åçˆ¬èŸ²æ©Ÿåˆ¶ï¼‰")
        except Exception as e:
            logger.warning(f"âš ï¸ MacroMicro æ•¸æ“šæ”¶é›†å¤±æ•—: {str(e)}")
        
        # === æ–°å¢å¢å¼·æ•¸æ“šæº ===
        
        # éš¨æ©Ÿå»¶é²
        time.sleep(random.uniform(3, 5))
        
        # 4. æ”¶é›†å¢å¼·æ•¸æ“šæº
        logger.info("ğŸ”¥ æ”¶é›†å¢å¼·æ•¸æ“šæºï¼ˆFX678ã€CMEã€Investing.comã€CNNï¼‰...")
        try:
            enhanced_data = self.enhanced_scraper.scrape_all_enhanced_sources()
            if enhanced_data and enhanced_data.get('sources'):
                results['enhanced_sources'] = enhanced_data
                logger.info(f"âœ… å¢å¼·æ•¸æ“šæºæ”¶é›†æˆåŠŸï¼ŒæˆåŠŸç‡: {enhanced_data['summary']['success_rate']}")
                logger.info(f"ğŸ“Š å¯é æ€§è©•åˆ†: {enhanced_data['summary']['reliability_score']}/100")
            else:
                logger.warning("âš ï¸ å¢å¼·æ•¸æ“šæºç²å–å¤±æ•—")
        except Exception as e:
            logger.error(f"âŒ å¢å¼·æ•¸æ“šæºæ”¶é›†å¤±æ•—: {str(e)}")
        
        # 5. é€²è¡Œç¶œåˆåˆ†æï¼ˆæ•´åˆæ‰€æœ‰æ•¸æ“šæºï¼‰
        logger.info("ğŸ§  é€²è¡Œå¸‚å ´ç’°å¢ƒç¶œåˆåˆ†æ...")
        analysis = self._analyze_market_environment_enhanced(
            results['data_sources'], 
            results['enhanced_sources']
        )
        results['analysis'] = analysis
        
        # 6. è©•ä¼°æ•¸æ“šå¯é æ€§
        reliability = self._assess_data_reliability(
            results['data_sources'], 
            results['enhanced_sources']
        )
        results['reliability_assessment'] = reliability
        
        logger.info("âœ… ç¬¬ä¸€å±¤æ•¸æ“šæ”¶é›†å®Œæˆï¼ˆå¢å¼·ç‰ˆï¼‰")
        logger.info(f"ğŸ“ˆ ç¸½é«”å¯é æ€§: {reliability['overall_reliability']}")
        
        return results
    
    def _analyze_market_environment_enhanced(self, original_sources, enhanced_sources):
        """å¢å¼·ç‰ˆå¸‚å ´ç’°å¢ƒåˆ†æ"""
        analysis = {
            'market_sentiment': 'Unknown',
            'economic_indicators': {},
            'market_phase': 'æœªçŸ¥',
            'risk_appetite': 'ä¸­æ€§',
            'investment_environment': 'è¬¹æ…',
            'confidence_level': 50,
            'key_factors': [],
            'data_cross_validation': {}
        }
        
        try:
            # === å¸‚å ´æƒ…ç·’åˆ†æï¼ˆå¤šæºäº¤å‰é©—è­‰ï¼‰===
            sentiment_sources = []
            
            # Alternative.me Fear & Greed
            if 'fear_greed' in original_sources:
                fg_data = original_sources['fear_greed']
                sentiment_sources.append({
                    'source': 'Alternative.me',
                    'value': fg_data['index_value'],
                    'sentiment': fg_data['sentiment'],
                    'weight': 0.4
                })
            
            # CNN Fear & Greed
            if enhanced_sources and 'cnn_fear_greed' in enhanced_sources.get('sources', {}):
                cnn_data = enhanced_sources['sources']['cnn_fear_greed']['data']
                sentiment_sources.append({
                    'source': 'CNN',
                    'value': cnn_data['fear_greed_index'],
                    'sentiment': cnn_data['sentiment'],
                    'weight': 0.3
                })
            
            # è¨ˆç®—åŠ æ¬Šå¹³å‡æƒ…ç·’æŒ‡æ•¸
            if sentiment_sources:
                weighted_sentiment = sum(s['value'] * s['weight'] for s in sentiment_sources)
                total_weight = sum(s['weight'] for s in sentiment_sources)
                avg_sentiment = weighted_sentiment / total_weight if total_weight > 0 else 50
                
                analysis['market_sentiment'] = self._classify_sentiment(avg_sentiment)
                analysis['sentiment_index'] = round(avg_sentiment)
                analysis['data_cross_validation']['sentiment'] = {
                    'sources': sentiment_sources,
                    'weighted_average': round(avg_sentiment),
                    'consensus': len(sentiment_sources) >= 2
                }
            
            # === ç¶“æ¿ŸæŒ‡æ¨™åˆ†æï¼ˆå¤šæºæ•´åˆï¼‰===
            economic_data = {}
            
            # FREDæ•¸æ“š
            if 'fred' in original_sources:
                fred_data = original_sources['fred']
                economic_data.update({
                    'gdp_growth': fred_data.get('gdp_growth', 2.0),
                    'unemployment_rate': fred_data.get('unemployment_rate', 4.0),
                    'inflation_rate': fred_data.get('inflation_rate', 3.0)
                })
            
            # FX678 CPIæ•¸æ“š
            if enhanced_sources and 'fx678_cpi' in enhanced_sources.get('sources', {}):
                fx678_data = enhanced_sources['sources']['fx678_cpi']['data']
                economic_data['cpi_fx678'] = fx678_data['cpi_annual']
                economic_data['inflation_status'] = fx678_data['status']
            
            # Investing.comå°±æ¥­æ•¸æ“š
            if enhanced_sources and 'investing_employment' in enhanced_sources.get('sources', {}):
                inv_data = enhanced_sources['sources']['investing_employment']['data']
                if 'unemployment_rate' in inv_data:
                    economic_data['unemployment_investing'] = inv_data['unemployment_rate']
                if 'nonfarm_payrolls' in inv_data:
                    economic_data['nonfarm_payrolls'] = inv_data['nonfarm_payrolls']
                economic_data['employment_health'] = inv_data['employment_health']
            
            # CME FedWatchåˆ©ç‡é æœŸ
            if enhanced_sources and 'cme_fedwatch' in enhanced_sources.get('sources', {}):
                cme_data = enhanced_sources['sources']['cme_fedwatch']['data']
                economic_data['fed_rate_probability'] = cme_data['max_probability']
                economic_data['fed_outlook'] = cme_data['fed_outlook']
            
            analysis['economic_indicators'] = economic_data
            
            # === å¸‚å ´éšæ®µåˆ¤æ–· ===
            market_phase = self._determine_market_phase_enhanced(analysis)
            analysis['market_phase'] = market_phase
            
            # === é¢¨éšªåå¥½è©•ä¼° ===
            risk_appetite = self._assess_risk_appetite_enhanced(analysis)
            analysis['risk_appetite'] = risk_appetite
            
            # === æŠ•è³‡ç’°å¢ƒè©•ä¼° ===
            investment_env = self._assess_investment_environment_enhanced(analysis)
            analysis['investment_environment'] = investment_env
            
            # === ä¿¡å¿ƒæ°´æº–è¨ˆç®— ===
            confidence = self._calculate_confidence_level_enhanced(
                original_sources, enhanced_sources, analysis
            )
            analysis['confidence_level'] = confidence
            
            # === é—œéµå› ç´ è­˜åˆ¥ ===
            key_factors = self._identify_key_factors_enhanced(analysis)
            analysis['key_factors'] = key_factors
            
        except Exception as e:
            logger.error(f"å¢å¼·ç‰ˆå¸‚å ´ç’°å¢ƒåˆ†æå¤±æ•—: {str(e)}")
            analysis['key_factors'].append(f'åˆ†æéŒ¯èª¤: {str(e)}')
        
        return analysis
    
    def _assess_data_reliability(self, original_sources, enhanced_sources):
        """è©•ä¼°æ•¸æ“šå¯é æ€§"""
        reliability = {
            'original_sources_count': len(original_sources),
            'enhanced_sources_count': len(enhanced_sources.get('sources', {})) if enhanced_sources else 0,
            'total_sources': 0,
            'reliability_score': 0,
            'overall_reliability': 'ä½',
            'source_details': {}
        }
        
        # è¨ˆç®—ç¸½æ•¸æ“šæºæ•¸é‡
        reliability['total_sources'] = reliability['original_sources_count'] + reliability['enhanced_sources_count']
        
        # è¨ˆç®—å¯é æ€§è©•åˆ†
        base_score = reliability['original_sources_count'] * 20  # åŸå§‹æ•¸æ“šæºæ¯å€‹20åˆ†
        enhanced_score = enhanced_sources.get('summary', {}).get('reliability_score', 0) if enhanced_sources else 0
        
        reliability['reliability_score'] = base_score + enhanced_score
        
        # è©•ä¼°æ•´é«”å¯é æ€§
        if reliability['reliability_score'] >= 80:
            reliability['overall_reliability'] = 'å¾ˆé«˜'
        elif reliability['reliability_score'] >= 60:
            reliability['overall_reliability'] = 'é«˜'
        elif reliability['reliability_score'] >= 40:
            reliability['overall_reliability'] = 'ä¸­ç­‰'
        elif reliability['reliability_score'] >= 20:
            reliability['overall_reliability'] = 'ä½'
        else:
            reliability['overall_reliability'] = 'å¾ˆä½'
        
        # è©³ç´°ä¾†æºä¿¡æ¯
        for source in original_sources:
            reliability['source_details'][source] = {
                'type': 'original',
                'status': 'success',
                'reliability': 'medium'
            }
        
        if enhanced_sources and 'sources' in enhanced_sources:
            for source, data in enhanced_sources['sources'].items():
                reliability['source_details'][source] = {
                    'type': 'enhanced',
                    'status': 'success',
                    'reliability': data.get('reliability', 'medium')
                }
        
        return reliability
    
    def _classify_sentiment(self, score):
        """åˆ†é¡å¸‚å ´æƒ…ç·’"""
        if score >= 75:
            return "æ¥µåº¦è²ªå©ª"
        elif score >= 55:
            return "è²ªå©ª"
        elif score >= 45:
            return "ä¸­æ€§"
        elif score >= 25:
            return "ææ‡¼"
        else:
            return "æ¥µåº¦ææ‡¼"
    
    def _determine_market_phase_enhanced(self, analysis):
        """å¢å¼·ç‰ˆå¸‚å ´éšæ®µåˆ¤æ–·"""
        sentiment_index = analysis.get('sentiment_index', 50)
        economic_indicators = analysis.get('economic_indicators', {})
        
        # åŸºæ–¼å¤šå€‹æŒ‡æ¨™åˆ¤æ–·
        if sentiment_index > 70 and economic_indicators.get('gdp_growth', 0) > 3:
            return "ç‰›å¸‚å¾ŒæœŸ"
        elif sentiment_index > 55 and economic_indicators.get('unemployment_rate', 10) < 5:
            return "ç‰›å¸‚ä¸­æœŸ"
        elif sentiment_index < 30:
            return "ç†Šå¸‚"
        elif sentiment_index < 45:
            return "ä¿®æ­£æœŸ"
        else:
            return "ç›¤æ•´æœŸ"
    
    def _assess_risk_appetite_enhanced(self, analysis):
        """å¢å¼·ç‰ˆé¢¨éšªåå¥½è©•ä¼°"""
        sentiment_index = analysis.get('sentiment_index', 50)
        
        if sentiment_index > 70:
            return "é«˜é¢¨éšªåå¥½"
        elif sentiment_index > 55:
            return "ä¸­é«˜é¢¨éšªåå¥½"
        elif sentiment_index > 45:
            return "ä¸­æ€§"
        elif sentiment_index > 30:
            return "ä½é¢¨éšªåå¥½"
        else:
            return "æ¥µä½é¢¨éšªåå¥½"
    
    def _assess_investment_environment_enhanced(self, analysis):
        """å¢å¼·ç‰ˆæŠ•è³‡ç’°å¢ƒè©•ä¼°"""
        sentiment = analysis.get('market_sentiment', 'ä¸­æ€§')
        phase = analysis.get('market_phase', 'ç›¤æ•´æœŸ')
        
        if sentiment in ['æ¥µåº¦è²ªå©ª'] or phase == 'ç‰›å¸‚å¾ŒæœŸ':
            return "è¬¹æ…"
        elif sentiment in ['è²ªå©ª'] or phase == 'ç‰›å¸‚ä¸­æœŸ':
            return "ç©æ¥µ"
        elif sentiment in ['æ¥µåº¦ææ‡¼'] or phase == 'ç†Šå¸‚':
            return "æ©Ÿæœƒ"
        else:
            return "å¹³è¡¡"
    
    def _calculate_confidence_level_enhanced(self, original_sources, enhanced_sources, analysis):
        """å¢å¼·ç‰ˆä¿¡å¿ƒæ°´æº–è¨ˆç®—"""
        base_confidence = 30
        
        # æ•¸æ“šæºæ•¸é‡åŠ åˆ†
        source_count = len(original_sources) + len(enhanced_sources.get('sources', {})) if enhanced_sources else 0
        source_bonus = min(source_count * 10, 40)
        
        # æ•¸æ“šä¸€è‡´æ€§åŠ åˆ†
        consistency_bonus = 0
        if 'data_cross_validation' in analysis:
            if analysis['data_cross_validation'].get('sentiment', {}).get('consensus'):
                consistency_bonus += 20
        
        # å¯é æ€§è©•åˆ†åŠ åˆ†
        reliability_bonus = 0
        if enhanced_sources:
            reliability_score = enhanced_sources.get('summary', {}).get('reliability_score', 0)
            reliability_bonus = min(reliability_score // 5, 10)
        
        total_confidence = base_confidence + source_bonus + consistency_bonus + reliability_bonus
        return min(total_confidence, 95)  # æœ€é«˜95%
    
    def _identify_key_factors_enhanced(self, analysis):
        """å¢å¼·ç‰ˆé—œéµå› ç´ è­˜åˆ¥"""
        factors = []
        
        # å¸‚å ´æƒ…ç·’å› ç´ 
        sentiment = analysis.get('market_sentiment', 'ä¸­æ€§')
        if sentiment in ['æ¥µåº¦è²ªå©ª', 'æ¥µåº¦ææ‡¼']:
            factors.append(f'å¸‚å ´æƒ…ç·’{sentiment}ï¼Œéœ€ç‰¹åˆ¥é—œæ³¨')
        
        # ç¶“æ¿ŸæŒ‡æ¨™å› ç´ 
        economic = analysis.get('economic_indicators', {})
        if 'inflation_status' in economic:
            factors.append(f'é€šè†¨ç‹€æ³ï¼š{economic["inflation_status"]}')
        
        if 'employment_health' in economic:
            factors.append(f'å°±æ¥­å¸‚å ´ï¼š{economic["employment_health"]}')
        
        if 'fed_outlook' in economic:
            factors.append(f'è¯æº–æœƒæ”¿ç­–ï¼š{economic["fed_outlook"]}')
        
        # å¸‚å ´éšæ®µå› ç´ 
        phase = analysis.get('market_phase', 'ç›¤æ•´æœŸ')
        if phase in ['ç‰›å¸‚å¾ŒæœŸ', 'ç†Šå¸‚']:
            factors.append(f'å¸‚å ´è™•æ–¼{phase}ï¼Œéœ€èª¿æ•´ç­–ç•¥')
        
        return factors
    
    def get_summary_report(self):
        """ç²å–æ‘˜è¦å ±å‘Šï¼ˆå¢å¼·ç‰ˆï¼‰"""
        data = self.collect_all_data()
        
        report = {
            'timestamp': data['timestamp'],
            'summary': {},
            'recommendations': [],
            'data_quality': {},
            'reliability': data.get('reliability_assessment', {})
        }
        
        # æ•¸æ“šå“è³ªè©•ä¼°
        original_count = len(data['data_sources'])
        enhanced_count = len(data['enhanced_sources'].get('sources', {})) if data['enhanced_sources'] else 0
        total_sources = original_count + enhanced_count
        
        report['data_quality'] = {
            'original_sources': original_count,
            'enhanced_sources': enhanced_count,
            'total_sources': total_sources,
            'success_rate': f"{(total_sources/6)*100:.1f}%",  # ç¸½å…±6å€‹å¯èƒ½çš„æ•¸æ“šæº
            'available_data': list(data['data_sources'].keys()) + list(data['enhanced_sources'].get('sources', {}).keys()) if data['enhanced_sources'] else []
        }
        
        # æ‘˜è¦ä¿¡æ¯
        analysis = data.get('analysis', {})
        if analysis:
            report['summary'] = {
                'market_sentiment': analysis.get('market_sentiment', 'æœªçŸ¥'),
                'sentiment_index': analysis.get('sentiment_index', 50),
                'market_phase': analysis.get('market_phase', 'æœªçŸ¥'),
                'investment_environment': analysis.get('investment_environment', 'è¬¹æ…'),
                'confidence_level': analysis.get('confidence_level', 50)
            }
            
            # æŠ•è³‡å»ºè­°
            env = analysis.get('investment_environment', 'è¬¹æ…')
            if env == 'æ©Ÿæœƒ':
                report['recommendations'].append('å¸‚å ´ææ…Œæä¾›è²·å…¥æ©Ÿæœƒï¼Œå»ºè­°åˆ†æ‰¹é€²å ´')
            elif env == 'ç©æ¥µ':
                report['recommendations'].append('å¸‚å ´æƒ…ç·’è‰¯å¥½ï¼Œå¯ç©æ¥µåƒèˆ‡ä½†éœ€è¨­å®šåœæ')
            elif env == 'è¬¹æ…':
                report['recommendations'].append('å¸‚å ´éç†±ï¼Œå»ºè­°è¬¹æ…æ“ä½œæˆ–ç²åˆ©äº†çµ')
            else:
                report['recommendations'].append('å¸‚å ´æƒ…ç·’ä¸­æ€§ï¼Œå»ºè­°å¹³è¡¡é…ç½®ç­‰å¾…æ˜ç¢ºä¿¡è™Ÿ')
        
        return report
    
    def close(self):
        """é—œé–‰æ‰€æœ‰è³‡æº"""
        try:
            self.fear_greed_scraper.__exit__(None, None, None)
            self.macromicro_scraper.close()
            self.fred_scraper.__exit__(None, None, None)
        except:
            pass
    
    def __enter__(self):
        return self
    
    def __exit__(self, exc_type, exc_val, exc_tb):
        self.close()

def main():
    """ä¸»å‡½æ•¸ - æ¼”ç¤ºç”¨æ³•"""
    with Layer1Collector() as collector:
        # ç²å–å®Œæ•´æ•¸æ“š
        full_data = collector.collect_all_data()
        
        print("\n" + "="*60)
        print("ğŸ“Š ç¬¬ä¸€å±¤ç¸½ç¶“æ•¸æ“šæ”¶é›†çµæœ")
        print("="*60)
        
        # é¡¯ç¤ºæ‘˜è¦å ±å‘Š
        summary = collector.get_summary_report()
        
        print(f"\nğŸ• æ™‚é–“: {summary['timestamp'][:19]}")
        print(f"ğŸ“ˆ å¸‚å ´æƒ…ç·’: {summary['summary'].get('market_sentiment', 'N/A')}")
        print(f"ğŸ›ï¸ ç¶“æ¿Ÿéšæ®µ: {summary['summary'].get('market_phase', 'N/A')}")
        print(f"ğŸ’¡ æŠ•è³‡å»ºè­°: {summary['summary'].get('investment_environment', 'N/A')}")
        print(f"âš ï¸ é¢¨éšªç­‰ç´š: {summary['summary'].get('risk_appetite', 'N/A')}")
        
        print(f"\nğŸ“Š æ•¸æ“šå“è³ª:")
        print(f"   æˆåŠŸç‡: {summary['data_quality']['success_rate']}")
        print(f"   å¯ç”¨æ•¸æ“šæº: {', '.join(summary['data_quality']['available_data'])}")
        
        if summary['recommendations']:
            print(f"\nğŸ’¡ é—œéµå› ç´ :")
            for i, rec in enumerate(summary['recommendations'][:5], 1):
                print(f"   {i}. {rec}")

if __name__ == "__main__":
    main() 